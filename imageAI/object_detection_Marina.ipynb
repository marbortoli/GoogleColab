{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "object_detection_Marina.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "18IuKK5MBQTKHI_rgGCnzn0DRL0rHI5dT",
      "authorship_tag": "ABX9TyNzzVaEn50IE533fwxWi5dZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marbortoli/GoogleColab/blob/main/object_detection_Marina.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGs0VMuuPb28",
        "outputId": "79202108-fe31-4c20-f087-5d32c553170c"
      },
      "source": [
        "# get the dataset for the first example\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KScsqSQ8bPkB",
        "outputId": "440866cd-fbec-433e-9573-0e18bd1a661d"
      },
      "source": [
        "!ls gdrive/MyDrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 20200826_Money.xlsx   LA011.jpeg   scada_all.zip   TFODCourse\n",
            "'Colab Notebooks'      OLD\t    scada_one.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AqxZXWbawG9",
        "outputId": "d365540e-f679-41a1-b4ed-2eed6538299f"
      },
      "source": [
        "!unzip gdrive/MyDrive/scada_one.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  gdrive/MyDrive/scada_one.zip\n",
            "   creating: scada_one/train/\n",
            "   creating: scada_one/train/annotations/\n",
            "  inflating: scada_one/train/annotations/004.xml  \n",
            "  inflating: scada_one/train/annotations/005.xml  \n",
            "  inflating: scada_one/train/annotations/007.xml  \n",
            "  inflating: scada_one/train/annotations/009.xml  \n",
            "  inflating: scada_one/train/annotations/011.xml  \n",
            "  inflating: scada_one/train/annotations/013.xml  \n",
            "  inflating: scada_one/train/annotations/015.xml  \n",
            "  inflating: scada_one/train/annotations/016.xml  \n",
            "   creating: scada_one/train/images/\n",
            " extracting: scada_one/train/images/004.PNG  \n",
            " extracting: scada_one/train/images/005.PNG  \n",
            " extracting: scada_one/train/images/007.PNG  \n",
            " extracting: scada_one/train/images/009.PNG  \n",
            " extracting: scada_one/train/images/011.PNG  \n",
            " extracting: scada_one/train/images/013.PNG  \n",
            " extracting: scada_one/train/images/015.PNG  \n",
            " extracting: scada_one/train/images/016.PNG  \n",
            "   creating: scada_one/validation/\n",
            "   creating: scada_one/validation/annotations/\n",
            "  inflating: scada_one/validation/annotations/003.xml  \n",
            "  inflating: scada_one/validation/annotations/006.xml  \n",
            "  inflating: scada_one/validation/annotations/008.xml  \n",
            "  inflating: scada_one/validation/annotations/010.xml  \n",
            "  inflating: scada_one/validation/annotations/012.xml  \n",
            "  inflating: scada_one/validation/annotations/014.xml  \n",
            "   creating: scada_one/validation/images/\n",
            " extracting: scada_one/validation/images/003.PNG  \n",
            " extracting: scada_one/validation/images/006.PNG  \n",
            " extracting: scada_one/validation/images/008.PNG  \n",
            " extracting: scada_one/validation/images/010.PNG  \n",
            " extracting: scada_one/validation/images/012.PNG  \n",
            " extracting: scada_one/validation/images/014.PNG  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuyewmLoieY-"
      },
      "source": [
        "!pip3 install tensorflow>=2.4.0\n",
        "!pip install keras>=2.4.3 numpy>=1.19.3 pillow>=7.0.0 scipy>=1.4.1 h5py>=2.10.0 matplotlib>=3.3.2 opencv-python keras-resnet>=0.2.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VS_cc863ikFg",
        "outputId": "80ec7d25-d8f9-4191-fa8c-87d84e7489db"
      },
      "source": [
        "# image AI\n",
        "!pip install imageai --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting imageai\n",
            "  Downloading imageai-2.1.6-py3-none-any.whl (160 kB)\n",
            "\u001b[?25l\r\u001b[K     |██                              | 10 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |████                            | 20 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████                          | 30 kB 16.6 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 40 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 51 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 61 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 81 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 92 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 102 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 112 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 122 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 133 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 143 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 153 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 160 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from imageai) (1.4.1)\n",
            "Requirement already satisfied: keras-resnet==0.2.0 in /usr/local/lib/python3.7/dist-packages (from imageai) (0.2.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imageai) (4.1.2.30)\n",
            "Collecting numpy==1.19.3\n",
            "  Downloading numpy-1.19.3-cp37-cp37m-manylinux2010_x86_64.whl (14.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9 MB 108 kB/s \n",
            "\u001b[?25hCollecting pillow==7.0.0\n",
            "  Downloading Pillow-7.0.0-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 11.3 MB/s \n",
            "\u001b[?25hCollecting keras==2.4.3\n",
            "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 45.0 MB/s \n",
            "\u001b[?25hCollecting matplotlib==3.3.2\n",
            "  Downloading matplotlib-3.3.2-cp37-cp37m-manylinux1_x86_64.whl (11.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.6 MB 33.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0->imageai) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3->imageai) (3.13)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (1.3.2)\n",
            "Requirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (2021.5.30)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (2.8.2)\n",
            "Installing collected packages: numpy, h5py, pillow, keras, matplotlib, imageai\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.6.0\n",
            "    Uninstalling keras-2.6.0:\n",
            "      Successfully uninstalled keras-2.6.0\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.6.0 requires h5py~=3.1.0, but you have h5py 2.10.0 which is incompatible.\n",
            "tensorflow 2.6.0 requires keras~=2.6, but you have keras 2.4.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "bokeh 2.3.3 requires pillow>=7.1.0, but you have pillow 7.0.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed h5py-2.10.0 imageai-2.1.6 keras-2.4.3 matplotlib-3.3.2 numpy-1.19.3 pillow-7.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UK4k_SS3ixA0",
        "outputId": "a1b05481-ca9c-44b1-af81-f44dfef25d91"
      },
      "source": [
        "# detection model training\n",
        "## start with a pre trained model\n",
        "### ImageAI provides the option to train with and without transfer learning. Strongly recommend you use transfer learning except you have thousands of object samples in your dataset\n",
        "\n",
        "!wget https://github.com/OlafenwaMoses/ImageAI/releases/download/essential-v4/pretrained-yolov3.h5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-13 13:15:39--  https://github.com/OlafenwaMoses/ImageAI/releases/download/essential-v4/pretrained-yolov3.h5\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/125932201/12701d80-b2ab-11e9-9f56-c06e1dfbec05?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211013%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211013T131539Z&X-Amz-Expires=300&X-Amz-Signature=7dccd004b5836ff2d3cb98717a220223ce4ee5c7ddf3796935a7c3d1c950ec02&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=125932201&response-content-disposition=attachment%3B%20filename%3Dpretrained-yolov3.h5&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-10-13 13:15:39--  https://github-releases.githubusercontent.com/125932201/12701d80-b2ab-11e9-9f56-c06e1dfbec05?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211013%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211013T131539Z&X-Amz-Expires=300&X-Amz-Signature=7dccd004b5836ff2d3cb98717a220223ce4ee5c7ddf3796935a7c3d1c950ec02&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=125932201&response-content-disposition=attachment%3B%20filename%3Dpretrained-yolov3.h5&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.108.154, 185.199.109.154, 185.199.110.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.108.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248671664 (237M) [application/octet-stream]\n",
            "Saving to: ‘pretrained-yolov3.h5’\n",
            "\n",
            "pretrained-yolov3.h 100%[===================>] 237.15M  97.4MB/s    in 2.4s    \n",
            "\n",
            "2021-10-13 13:15:41 (97.4 MB/s) - ‘pretrained-yolov3.h5’ saved [248671664/248671664]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz3JqqkVqUPB"
      },
      "source": [
        "**Training the code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8JomeEvoPCR",
        "outputId": "f88b062b-80d3-474b-ec10-617ad10ffc05"
      },
      "source": [
        "from imageai.Detection.Custom import DetectionModelTrainer\n",
        "\n",
        "trainer = DetectionModelTrainer() # class\n",
        "trainer.setModelTypeAsYOLOv3() # set out model type to YOLOv3\n",
        "trainer.setDataDirectory(data_directory=\"scada_one\") # set the path to my own custom dataset\n",
        "# specify the parameters: \n",
        "### object_names_array: array of the names of all the objects in my dataset\n",
        "#### ps.: for multiple objects in my annotation folder follow:\n",
        "##### object_names_array = [\"object_name_1\", \"object_name_2\", \"object_name_3\"]\n",
        "### batch_size: batch size for the training (larger the batch size - better detection accuracy)\n",
        "### num_experiments: n of times the train code iterate on my custom dataset\n",
        "### train_from_pretrained_model: leverage transfer learning using the pretrained YOLOv3 model\n",
        "trainer.setTrainConfig(object_names_array=[\"scada\"], batch_size=4, num_experiments=100, train_from_pretrained_model=\"pretrained-yolov3.h5\")\n",
        "trainer.trainModel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating anchor boxes for training images and annotation...\n",
            "Average IOU for 9 anchors: 0.94\n",
            "Anchor Boxes generated.\n",
            "Detection configuration saved in  scada_one/json/detection_config.json\n",
            "Evaluating over 6 samples taken from scada_one/validation\n",
            "Training over 8 samples  given at scada_one/train\n",
            "Training on: \t['scada']\n",
            "Training with Batch Size:  4\n",
            "Number of Training Samples:  8\n",
            "Number of Validation Samples:  6\n",
            "Number of Experiments:  100\n",
            "Training with transfer learning from pretrained Model\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer YoloLayer has arguments in `__init__` and therefore must override `get_config`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1969: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:4212: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "16/16 [==============================] - 66s 2s/step - loss: 137.9013 - yolo_layer_loss: 16.0198 - yolo_layer_1_loss: 37.2954 - yolo_layer_2_loss: 73.0080 - val_loss: 158.8830 - val_yolo_layer_loss: 21.0950 - val_yolo_layer_1_loss: 41.8973 - val_yolo_layer_2_loss: 84.3125\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 23s 1s/step - loss: 107.9929 - yolo_layer_loss: 11.0614 - yolo_layer_1_loss: 29.1053 - yolo_layer_2_loss: 56.2477 - val_loss: 134.7933 - val_yolo_layer_loss: 17.3309 - val_yolo_layer_1_loss: 34.6742 - val_yolo_layer_2_loss: 71.2094\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 22s 1s/step - loss: 92.9144 - yolo_layer_loss: 9.3802 - yolo_layer_1_loss: 23.4920 - yolo_layer_2_loss: 48.4632 - val_loss: 124.5739 - val_yolo_layer_loss: 13.9767 - val_yolo_layer_1_loss: 29.5669 - val_yolo_layer_2_loss: 69.4509\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 22s 1s/step - loss: 70.9667 - yolo_layer_loss: 7.3123 - yolo_layer_1_loss: 18.8100 - yolo_layer_2_loss: 33.2649 - val_loss: 107.6485 - val_yolo_layer_loss: 11.0274 - val_yolo_layer_1_loss: 25.1390 - val_yolo_layer_2_loss: 59.9023\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 22s 1s/step - loss: 58.6032 - yolo_layer_loss: 6.4948 - yolo_layer_1_loss: 15.3253 - yolo_layer_2_loss: 25.2035 - val_loss: 89.5378 - val_yolo_layer_loss: 9.8305 - val_yolo_layer_1_loss: 20.0174 - val_yolo_layer_2_loss: 48.1105\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 27s 2s/step - loss: 50.7921 - yolo_layer_loss: 5.8908 - yolo_layer_1_loss: 13.8449 - yolo_layer_2_loss: 19.4775 - val_loss: 71.4420 - val_yolo_layer_loss: 6.6281 - val_yolo_layer_1_loss: 16.1880 - val_yolo_layer_2_loss: 37.0477\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 21s 1s/step - loss: 43.3410 - yolo_layer_loss: 4.2014 - yolo_layer_1_loss: 11.7472 - yolo_layer_2_loss: 15.8156 - val_loss: 67.6082 - val_yolo_layer_loss: 5.2763 - val_yolo_layer_1_loss: 16.7247 - val_yolo_layer_2_loss: 34.0327\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 22s 1s/step - loss: 42.7843 - yolo_layer_loss: 5.0355 - yolo_layer_1_loss: 11.9522 - yolo_layer_2_loss: 14.2247 - val_loss: 64.0987 - val_yolo_layer_loss: 6.2667 - val_yolo_layer_1_loss: 13.5424 - val_yolo_layer_2_loss: 32.7200\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 20s 1s/step - loss: 37.6642 - yolo_layer_loss: 3.3127 - yolo_layer_1_loss: 10.8344 - yolo_layer_2_loss: 11.9496 - val_loss: 53.5758 - val_yolo_layer_loss: 2.9458 - val_yolo_layer_1_loss: 13.2101 - val_yolo_layer_2_loss: 25.8560\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 22s 1s/step - loss: 36.5867 - yolo_layer_loss: 4.2698 - yolo_layer_1_loss: 9.2075 - yolo_layer_2_loss: 11.5500 - val_loss: 51.7776 - val_yolo_layer_loss: 5.3558 - val_yolo_layer_1_loss: 10.8509 - val_yolo_layer_2_loss: 24.0176\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 21s 1s/step - loss: 33.9202 - yolo_layer_loss: 4.0891 - yolo_layer_1_loss: 8.4526 - yolo_layer_2_loss: 9.8317 - val_loss: 49.0846 - val_yolo_layer_loss: 3.9692 - val_yolo_layer_1_loss: 11.4486 - val_yolo_layer_2_loss: 22.1270\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 22s 1s/step - loss: 36.2625 - yolo_layer_loss: 4.0219 - yolo_layer_1_loss: 8.8317 - yolo_layer_2_loss: 11.8747 - val_loss: 46.1477 - val_yolo_layer_loss: 5.6697 - val_yolo_layer_1_loss: 11.1945 - val_yolo_layer_2_loss: 17.7555\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 21s 1s/step - loss: 32.6790 - yolo_layer_loss: 3.1812 - yolo_layer_1_loss: 8.6052 - yolo_layer_2_loss: 9.3705 - val_loss: 45.2567 - val_yolo_layer_loss: 4.7275 - val_yolo_layer_1_loss: 10.9718 - val_yolo_layer_2_loss: 18.0454\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 21s 1s/step - loss: 29.8250 - yolo_layer_loss: 1.9893 - yolo_layer_1_loss: 8.5042 - yolo_layer_2_loss: 7.8276 - val_loss: 39.3787 - val_yolo_layer_loss: 3.9207 - val_yolo_layer_1_loss: 10.4376 - val_yolo_layer_2_loss: 13.5256\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 21s 1s/step - loss: 30.3418 - yolo_layer_loss: 4.1612 - yolo_layer_1_loss: 7.4024 - yolo_layer_2_loss: 7.2901 - val_loss: 35.9173 - val_yolo_layer_loss: 2.3301 - val_yolo_layer_1_loss: 9.8572 - val_yolo_layer_2_loss: 12.2484\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 21s 1s/step - loss: 30.7098 - yolo_layer_loss: 5.2113 - yolo_layer_1_loss: 7.3627 - yolo_layer_2_loss: 6.6597 - val_loss: 32.6236 - val_yolo_layer_loss: 2.0499 - val_yolo_layer_1_loss: 9.8753 - val_yolo_layer_2_loss: 9.2282\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 21s 1s/step - loss: 26.0899 - yolo_layer_loss: 1.4910 - yolo_layer_1_loss: 7.4393 - yolo_layer_2_loss: 5.6903 - val_loss: 33.4092 - val_yolo_layer_loss: 3.5787 - val_yolo_layer_1_loss: 9.1430 - val_yolo_layer_2_loss: 9.2192\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 21s 1s/step - loss: 25.6603 - yolo_layer_loss: 2.7409 - yolo_layer_1_loss: 5.8189 - yolo_layer_2_loss: 5.6332 - val_loss: 33.5188 - val_yolo_layer_loss: 4.5640 - val_yolo_layer_1_loss: 8.5742 - val_yolo_layer_2_loss: 8.9142\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 21s 1s/step - loss: 26.8933 - yolo_layer_loss: 3.9287 - yolo_layer_1_loss: 5.6934 - yolo_layer_2_loss: 5.8060 - val_loss: 33.6651 - val_yolo_layer_loss: 5.3100 - val_yolo_layer_1_loss: 8.5044 - val_yolo_layer_2_loss: 8.3869\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 22s 1s/step - loss: 26.0401 - yolo_layer_loss: 3.7800 - yolo_layer_1_loss: 5.1373 - yolo_layer_2_loss: 5.6600 - val_loss: 32.5206 - val_yolo_layer_loss: 5.7202 - val_yolo_layer_1_loss: 7.8228 - val_yolo_layer_2_loss: 7.5163\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 22s 1s/step - loss: 27.9213 - yolo_layer_loss: 5.1671 - yolo_layer_1_loss: 5.3224 - yolo_layer_2_loss: 5.9706 - val_loss: 28.6058 - val_yolo_layer_loss: 1.8608 - val_yolo_layer_1_loss: 9.8620 - val_yolo_layer_2_loss: 5.4219\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 23s 1s/step - loss: 27.7611 - yolo_layer_loss: 4.8603 - yolo_layer_1_loss: 5.3746 - yolo_layer_2_loss: 6.0652 - val_loss: 30.5213 - val_yolo_layer_loss: 4.7102 - val_yolo_layer_1_loss: 8.3985 - val_yolo_layer_2_loss: 5.9518\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 22s 1s/step - loss: 25.9129 - yolo_layer_loss: 2.9286 - yolo_layer_1_loss: 5.7664 - yolo_layer_2_loss: 5.7570 - val_loss: 28.6983 - val_yolo_layer_loss: 2.5148 - val_yolo_layer_1_loss: 9.5544 - val_yolo_layer_2_loss: 5.1683\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 22s 1s/step - loss: 27.1032 - yolo_layer_loss: 3.7209 - yolo_layer_1_loss: 5.9167 - yolo_layer_2_loss: 6.0048 - val_loss: 28.8761 - val_yolo_layer_loss: 3.2664 - val_yolo_layer_1_loss: 9.1160 - val_yolo_layer_2_loss: 5.0329\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 21s 1s/step - loss: 25.1267 - yolo_layer_loss: 3.4913 - yolo_layer_1_loss: 4.7923 - yolo_layer_2_loss: 5.3824 - val_loss: 29.9310 - val_yolo_layer_loss: 4.7397 - val_yolo_layer_1_loss: 8.5506 - val_yolo_layer_2_loss: 5.1799\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 23s 1s/step - loss: 26.8232 - yolo_layer_loss: 4.4582 - yolo_layer_1_loss: 5.0565 - yolo_layer_2_loss: 5.8476 - val_loss: 28.9995 - val_yolo_layer_loss: 4.4895 - val_yolo_layer_1_loss: 8.0943 - val_yolo_layer_2_loss: 4.9548\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 23s 1s/step - loss: 27.0438 - yolo_layer_loss: 4.5513 - yolo_layer_1_loss: 5.0153 - yolo_layer_2_loss: 6.0164 - val_loss: 25.6323 - val_yolo_layer_loss: 0.9792 - val_yolo_layer_1_loss: 9.2996 - val_yolo_layer_2_loss: 3.8926\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 21s 1s/step - loss: 26.1862 - yolo_layer_loss: 3.6681 - yolo_layer_1_loss: 5.2335 - yolo_layer_2_loss: 5.8237 - val_loss: 28.4631 - val_yolo_layer_loss: 4.6642 - val_yolo_layer_1_loss: 8.0024 - val_yolo_layer_2_loss: 4.3357\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 22s 1s/step - loss: 26.6459 - yolo_layer_loss: 4.4411 - yolo_layer_1_loss: 5.1769 - yolo_layer_2_loss: 5.5671 - val_loss: 27.5644 - val_yolo_layer_loss: 4.2570 - val_yolo_layer_1_loss: 7.6817 - val_yolo_layer_2_loss: 4.1649\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 23s 1s/step - loss: 27.8445 - yolo_layer_loss: 4.7328 - yolo_layer_1_loss: 5.3456 - yolo_layer_2_loss: 6.3053 - val_loss: 27.1547 - val_yolo_layer_loss: 4.3494 - val_yolo_layer_1_loss: 7.0166 - val_yolo_layer_2_loss: 4.3279\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 22s 1s/step - loss: 25.8010 - yolo_layer_loss: 3.1239 - yolo_layer_1_loss: 5.6133 - yolo_layer_2_loss: 5.6029 - val_loss: 26.3496 - val_yolo_layer_loss: 3.1482 - val_yolo_layer_1_loss: 7.7493 - val_yolo_layer_2_loss: 3.9913\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 23s 1s/step - loss: 27.2776 - yolo_layer_loss: 4.8087 - yolo_layer_1_loss: 5.1120 - yolo_layer_2_loss: 5.8960 - val_loss: 27.7456 - val_yolo_layer_loss: 4.7151 - val_yolo_layer_1_loss: 7.3890 - val_yolo_layer_2_loss: 4.1806\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 21s 1s/step - loss: 25.9981 - yolo_layer_loss: 3.4867 - yolo_layer_1_loss: 5.3599 - yolo_layer_2_loss: 5.6906 - val_loss: 24.8209 - val_yolo_layer_loss: 1.1167 - val_yolo_layer_1_loss: 8.5784 - val_yolo_layer_2_loss: 3.6650\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 21s 1s/step - loss: 25.9915 - yolo_layer_loss: 3.4187 - yolo_layer_1_loss: 5.2070 - yolo_layer_2_loss: 5.9049 - val_loss: 26.2668 - val_yolo_layer_loss: 3.6181 - val_yolo_layer_1_loss: 7.3373 - val_yolo_layer_2_loss: 3.8505\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 20s 1s/step - loss: 25.0010 - yolo_layer_loss: 1.4284 - yolo_layer_1_loss: 6.8257 - yolo_layer_2_loss: 5.2862 - val_loss: 26.6907 - val_yolo_layer_loss: 3.7123 - val_yolo_layer_1_loss: 7.5741 - val_yolo_layer_2_loss: 3.9434\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 21s 1s/step - loss: 24.6258 - yolo_layer_loss: 2.0254 - yolo_layer_1_loss: 5.7933 - yolo_layer_2_loss: 5.3463 - val_loss: 25.6768 - val_yolo_layer_loss: 3.0693 - val_yolo_layer_1_loss: 7.3390 - val_yolo_layer_2_loss: 3.8076\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "Epoch 37/100\n",
            "14/16 [=========================>....] - ETA: 1s - loss: 24.8051 - yolo_layer_loss: 1.5200 - yolo_layer_1_loss: 5.6321 - yolo_layer_2_loss: 6.1921"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVi58aofqdXI"
      },
      "source": [
        "# **Evaluate model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhY9-6e5p2AB"
      },
      "source": [
        "# In the sample log shown above, new models are saved based on the decrease in the validation loss. In most cases, the lower the loss, the more accurate the model will be detecting objects in images and videos. However, some models may experience overfitting and still have lower losses. To ensure that you pick the best model for your custom detection, ImageAI allows you to evaluate the mAP (mean Average Precision, read more about it here) of all the trained models saved in the hololens/models folder.\n",
        "## The higher the mAP, the better the detection accuracy of the model.\n",
        "from imageai.Detection.Custom import DetectionModelTrainer\n",
        "\n",
        "trainer = DetectionModelTrainer()\n",
        "trainer.setModelTypeAsYOLOv3()\n",
        "## other pre trained model types\n",
        "#trainer.setModelTypeAsRetinaNet()\n",
        "#trainer.setModelTypeAsTinyYOLOv3()\n",
        "trainer.setDataDirectory(data_directory='scada_one')\n",
        "trainer.evaluateModel(model_path='scada_one/models', json_path='scada_one/json/detection_config.json', iou_threshold=0.5, object_threshold=0.3, nms_threshold=0.5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7k0PcfMis7C6"
      },
      "source": [
        "**Run custom detection code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLgESsldprxo"
      },
      "source": [
        "# get the image to find objects\n",
        "from google.colab import files\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRvE49xsK50d"
      },
      "source": [
        "\n",
        "img = cv2.imread('LA011.jpeg')\n",
        "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(img) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2Sx3upqs6db"
      },
      "source": [
        "from imageai.Detection.Custom import CustomObjectDetection\n",
        "\n",
        "detector = CustomObjectDetection()\n",
        "detector.setModelTypeAsYOLOv3()\n",
        "detector.setModelPath('scada_one/models/detection_model-ex-034--loss-0017.824.h5')\n",
        "detector.setJsonPath('scada_one/json/detection_config.json')\n",
        "detector.loadModel()\n",
        "detections = detector.detectObjectsFromImage(input_image='LA011.jpeg', output_image_path='obj_detected.jpg')\n",
        "for detection in detections:\n",
        "  print(detection['percentage_probability'], \" : \", detection['box_points'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZtcz9Cw0hF_"
      },
      "source": [
        "from imageai.Detection.Custom import CustomObjectDetection\n",
        "\n",
        "detector = CustomObjectDetection()\n",
        "detector.setModelTypeAsYOLOv3()\n",
        "detector.setModelPath('scada_one/models/detection_model-ex-034--loss-0017.824.h5')\n",
        "detector.setJsonPath('scada_one/json/detection_config.json')\n",
        "detector.loadModel()\n",
        "detections, extracted_objects_array = detector.detectObjectsFromImage(input_image='LA011.jpeg', output_image_path='obj_detected.jpg', extract_detected_objects=True)\n",
        "\n",
        "for detection, object_path in zip(detections, extracted_objects_array):\n",
        "  print(object_path)\n",
        "  print(detection['percentage_probability'], \" : \", detection['box_points'])\n",
        "  print('-----')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}