{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFOD_API.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN3JDEXqbI0i3rDbP2c2fMl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marbortoli/GoogleColab/blob/main/TFOD_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUHWnHQ8Rn_Q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Clone the tensorflow models repository if it doesn't already exist\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the Object Detection API\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "metadata": {
        "id": "DGwdmnjxRyJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import random\n",
        "import io\n",
        "import imageio\n",
        "import glob\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display, Javascript\n",
        "from IPython.display import Image as IPyImage\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.utils import colab_utils\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "wNYpBYeFRz97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: a file path.\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "def plot_detections(image_np,\n",
        "                    boxes,\n",
        "                    classes,\n",
        "                    scores,\n",
        "                    category_index,\n",
        "                    figsize=(12, 16),\n",
        "                    image_name=None):\n",
        "  \"\"\"Wrapper function to visualize detections.\n",
        "\n",
        "  Args:\n",
        "    image_np: uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    boxes: a numpy array of shape [N, 4]\n",
        "    classes: a numpy array of shape [N]. Note that class indices are 1-based,\n",
        "      and match the keys in the label map.\n",
        "    scores: a numpy array of shape [N] or None.  If scores=None, then\n",
        "      this function assumes that the boxes to be plotted are groundtruth\n",
        "      boxes and plot all boxes as black with no classes or scores.\n",
        "    category_index: a dict containing category dictionaries (each holding\n",
        "      category index `id` and category name `name`) keyed by category indices.\n",
        "    figsize: size for the figure.\n",
        "    image_name: a name for the image file.\n",
        "  \"\"\"\n",
        "  image_np_with_annotations = image_np.copy()\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np_with_annotations,\n",
        "      boxes,\n",
        "      classes,\n",
        "      scores,\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      min_score_thresh=0.8)\n",
        "  if image_name:\n",
        "    plt.imsave(image_name, image_np_with_annotations)\n",
        "  else:\n",
        "    plt.imshow(image_np_with_annotations)"
      ],
      "metadata": {
        "id": "ZxvUnj7hR3XJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# v7 pull dataset\n",
        "!pip install darwin-py\n",
        "#import darwin\n",
        "!darwin authenticate\n",
        "# api key: yjoOEYG.Q9JUmWG2o7jfqQ-SV3eLlRnzrO01Y7Yr\n",
        "\n",
        "!darwin dataset pull energy-machines-cloud-object-detection/train:train\n",
        "!darwin dataset pull energy-machines-cloud-object-detection/test_scada01:test\n",
        "!darwin dataset pull energy-machines-cloud-object-detection/valid:valid"
      ],
      "metadata": {
        "id": "GXzmFNlGR4Cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models/research/object_detection/dataset_tools/create_coco_tf_record.py \\\n",
        "      --logtostderr \\\n",
        "      --train_image_dir=\"/content/train/images/\" \\\n",
        "      --val_image_dir=\"/content/valid/images/\" \\\n",
        "      --test_image_dir=\"/content/test/images/\" \\\n",
        "      --train_annotations_file=\"/content/train/annotations/train.json/\" \\\n",
        "      --val_annotations_file=\"/content/valid/annotations/valid.json/\" \\\n",
        "      --testdev_annotations_file=\"/content/test/annotations/test.json/\" \\\n",
        "      --output_dir=\"/content/./\""
      ],
      "metadata": {
        "id": "81MPyVM1R9Sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_record_fname = '/content/coco_testdev.record*'\n",
        "train_record_fname ='/content/coco_train.record*'\n",
        "valid_record_fname ='/content/coco_val.record*'\n",
        "label_map_pbtxt_fname = '/content/scada_label_map.pbtxt'"
      ],
      "metadata": {
        "id": "E8jL3_04R_ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##choose model to deploy different models available in the TF2 object detection zoo\n",
        "MODELS_CONFIG = {\n",
        "    'efficientdet-d0': {\n",
        "        'model_name': 'efficientdet_d0_coco17_tpu-32',\n",
        "        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n",
        "        'batch_size': 16\n",
        "    },\n",
        "    'efficientdet-d1': {\n",
        "        'model_name': 'efficientdet_d1_coco17_tpu-32',\n",
        "        'base_pipeline_file': 'ssd_efficientdet_d1_640x640_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'efficientdet_d1_coco17_tpu-32.tar.gz',\n",
        "        'batch_size': 16\n",
        "    }\n",
        "}\n",
        "\n",
        "chosen_model = 'efficientdet-d0'\n",
        "\n",
        "num_steps = 40000 \n",
        "num_eval_steps = 500 \n",
        "\n",
        "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
        "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
        "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']\n",
        "batch_size = MODELS_CONFIG[chosen_model]['batch_size'] "
      ],
      "metadata": {
        "id": "NJK3DQyASB0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download pretrained weights\n",
        "%mkdir /content/models/research/deploy/\n",
        "%cd /content/models/research/deploy/\n",
        "import tarfile\n",
        "download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n",
        "\n",
        "!wget {download_tar}\n",
        "tar = tarfile.open(pretrained_checkpoint)\n",
        "tar.extractall()\n",
        "tar.close()"
      ],
      "metadata": {
        "id": "OKD28gdhSKrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download base training configuration file\n",
        "%cd /content/models/research/deploy\n",
        "download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n",
        "!wget {download_config}"
      ],
      "metadata": {
        "id": "HtBlIInSSQis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare\n",
        "pipeline_fname = '/content/models/research/deploy/' + base_pipeline_file\n",
        "fine_tune_checkpoint = '/content/models/research/deploy/' + model_name + '/checkpoint/ckpt-0'\n",
        "\n",
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n"
      ],
      "metadata": {
        "id": "TVBbcoXxST8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#change main parameters of base pipeline file to my own dataset\n",
        "\n",
        "import re\n",
        "\n",
        "%cd /content/models/research/deploy\n",
        "print('writing custom configuration file')\n",
        "\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open('pipeline_file.config', 'w') as f:\n",
        "    \n",
        " \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    \n",
        "    #fine-tune checkpoint type\n",
        "    s = re.sub(\n",
        "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
        "        \n",
        "    f.write(s)\n",
        "\n"
      ],
      "metadata": {
        "id": "cl_68p7-SVgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cat /content/models/research/deploy/pipeline_file.config"
      ],
      "metadata": {
        "id": "24rWZKT-SYYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%mkdir '/content/training' \n",
        "pipeline_file = '/content/models/research/deploy/pipeline_file.config'\n",
        "model_dir = '/content/training/'"
      ],
      "metadata": {
        "id": "vs2fks_1SijX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# it always has problem, so re install opencv\n",
        "!pip uninstall opencv-python-headless==4.5.5.62\n",
        "!pip install opencv-python-headless==4.5.2.52\n"
      ],
      "metadata": {
        "id": "PKqUtXKLSlI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN MODEL\n",
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_file} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --sample_1_of_n_eval_examples=1 \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "metadata": {
        "id": "U_xSCHh5Sqtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir '/content/training/train'"
      ],
      "metadata": {
        "id": "6bRruoOSSt5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#see where our model saved weights\n",
        "%ls '/content/training/'"
      ],
      "metadata": {
        "id": "QIGM02T4SxLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run conversion script\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "output_directory = '/content/fine_tuned_model'\n",
        "\n",
        "#place the model weights you would like to export here\n",
        "last_model_path = '/content/training/'\n",
        "print(last_model_path)\n",
        "!python /content/models/research/object_detection/exporter_main_v2.py \\\n",
        "    --trained_checkpoint_dir {last_model_path} \\\n",
        "    --output_directory {output_directory} \\\n",
        "    --pipeline_config_path {pipeline_file}"
      ],
      "metadata": {
        "id": "eiTFeqG4SyZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls '/content/fine_tuned_model/saved_model/'"
      ],
      "metadata": {
        "id": "4PqYsbLZSzx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start inference - same as https://colab.research.google.com/drive/1i3L17YExQ0IhomJTu8D8VSL4AluwN_vX?usp=sharing\n"
      ],
      "metadata": {
        "id": "Sn4iEnr6S0uA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "EQgCQ-0BS9Vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: the file path to the image\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)"
      ],
      "metadata": {
        "id": "bx8PLPXyS-Km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls '/content/training/'"
      ],
      "metadata": {
        "id": "puRC_ww8TALV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "\n",
        "filenames = list(pathlib.Path('/content/training/').glob('*.index'))\n",
        "\n",
        "filenames.sort()\n",
        "print(filenames)\n",
        "\n",
        "#recover our saved model\n",
        "pipeline_config = pipeline_file\n",
        "#generally you want to put the last ckpt from training in here\n",
        "model_dir = str(filenames[-1]).replace('.index','')\n",
        "configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n",
        "model_config = configs['model']\n",
        "detection_model = model_builder.build(\n",
        "      model_config=model_config, is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(\n",
        "      model=detection_model)\n",
        "ckpt.restore(os.path.join(str(filenames[-1]).replace('.index','')))\n",
        "\n",
        "\n",
        "def get_model_detection_function(model):\n",
        "  \"\"\"Get a tf.function for detection.\"\"\"\n",
        "\n",
        "  @tf.function\n",
        "  def detect_fn(image):\n",
        "    \"\"\"Detect objects in image.\"\"\"\n",
        "\n",
        "    image, shapes = model.preprocess(image)\n",
        "    prediction_dict = model.predict(image, shapes)\n",
        "    detections = model.postprocess(prediction_dict, shapes)\n",
        "\n",
        "    return detections, prediction_dict, tf.reshape(shapes, [-1])\n",
        "\n",
        "  return detect_fn\n",
        "\n",
        "detect_fn = get_model_detection_function(detection_model)"
      ],
      "metadata": {
        "id": "1HiqxnKATBI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#map labels for inference decoding\n",
        "label_map_path = label_map_pbtxt_fname #configs['eval_input_config'].label_map_path\n",
        "label_map = label_map_util.load_labelmap(label_map_path)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map,\n",
        "    max_num_classes=label_map_util.get_max_label_map_index(label_map),\n",
        "    use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)"
      ],
      "metadata": {
        "id": "m-Rd89jPTCav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run detector on test image\n",
        "#it takes a little longer on the first run and then runs at normal speed. \n",
        "import random\n",
        "\n",
        "TEST_IMAGE_PATHS = glob.glob('/content/train/images/*.png')\n",
        "image_path = random.choice(TEST_IMAGE_PATHS)\n",
        "image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "# Things to try:\n",
        "# Flip horizontally\n",
        "# image_np = np.fliplr(image_np).copy()\n",
        "\n",
        "# Convert image to grayscale\n",
        "# image_np = np.tile(\n",
        "#     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
        "\n",
        "input_tensor = tf.convert_to_tensor(\n",
        "    np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
        "\n",
        "label_id_offset = 1\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np_with_detections,\n",
        "      detections['detection_boxes'][0].numpy(),\n",
        "      (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n",
        "      detections['detection_scores'][0].numpy(),\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      max_boxes_to_draw=200,\n",
        "      min_score_thresh=.5,\n",
        "      agnostic_mode=False,\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(12,16))\n",
        "plt.imshow(image_np_with_detections)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LBnFCfCzTDbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# coordinates to build our HMI pages\n",
        "boxes = detections['detection_boxes'].numpy()[0]\n",
        "# get all boxes from an array\n",
        "max_boxes_to_draw = boxes.shape[0]\n",
        "# get scores to get a threshold\n",
        "scores = detections['detection_scores'].numpy()[0]\n",
        "# this is set as a default but feel free to adjust it to your needs\n",
        "min_score_thresh=.5\n",
        "# # iterate over all objects found\n",
        "coordinates = []\n",
        "for i in range(min(max_boxes_to_draw, boxes.shape[0])):\n",
        "    if scores[i] > min_score_thresh:\n",
        "        class_id = int(detections['detection_classes'].numpy()[0][i] + 1)\n",
        "        coordinates.append({\n",
        "            \"box\": boxes[i],\n",
        "            \"class_name\": category_index[class_id][\"name\"],\n",
        "            \"score\": scores[i]\n",
        "        })\n",
        "\n",
        "\"\"\"(left, right, top, bottom) = (xmin * im_width, xmax * im_width, \n",
        "                              ymin * im_height, ymax * im_height)\"\"\"\n",
        "print(coordinates)"
      ],
      "metadata": {
        "id": "IThNzKOjTQl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "!zip -r /content/training.zip /content/training\n",
        "!zip -r /content/fine_tuned_model/saved_model.zip /content/fine_tuned_model/saved_model\n",
        "from google.colab import files\n",
        "files.download('/content/training.zip')\n",
        "files.download('/content/models/research/deploy/pipeline_file.config')\n",
        "files.download('/content/fine_tuned_model/saved_model.zip')"
      ],
      "metadata": {
        "id": "13SIzvqATNtc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}