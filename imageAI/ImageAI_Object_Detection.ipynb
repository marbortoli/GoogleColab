{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageAI - Object Detection by Moses.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOLZG1zlXPDd/2TJZMcXY6y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marbortoli/GoogleColab/blob/main/ImageAI_Object_Detection_by_Moses.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFXZX7CQhaqw"
      },
      "source": [
        "# get dataset (google glasses from Moses) \n",
        "## name: hololens\n",
        "## image for trial: holo.JPG\n",
        "\n",
        "!wget https://github.com/OlafenwaMoses/ImageAI/releases/download/essential-v4/hololens.zip\n",
        "\n",
        "!unzip hololens.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qKLwmFMhnhP"
      },
      "source": [
        "# download a pre trained model - YOLOv3\n",
        "!wget https://github.com/OlafenwaMoses/ImageAI/releases/download/essential-v4/pretrained-yolov3.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SabIVUGh0wP"
      },
      "source": [
        "# necessary support\n",
        "!pip3 install tensorflow>=2.4.0\n",
        "!pip install keras>=2.4.3 numpy>=1.19.3 pillow>=7.0.0 scipy>=1.4.1 h5py>=2.10.0 matplotlib>=3.3.2 opencv-python keras-resnet>=0.2.0\n",
        "\n",
        "# image AI\n",
        "!pip install imageai --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUiTQa6Vh_Bu"
      },
      "source": [
        "# training model\n",
        "from imageai.Detection.Custom import DetectionModelTrainer\n",
        "\n",
        "trainer = DetectionModelTrainer() # class\n",
        "trainer.setModelTypeAsYOLOv3() # set out model type to YOLOv3\n",
        "trainer.setDataDirectory(data_directory=\"hololens\") # set the path to my own custom dataset\n",
        "# specify the parameters: \n",
        "### object_names_array: array of the names of all the objects in my dataset\n",
        "#### ps.: for multiple objects in my annotation folder follow:\n",
        "##### object_names_array = [\"object_name_1\", \"object_name_2\", \"object_name_3\"]\n",
        "### batch_size: batch size for the training (larger the batch size - better detection accuracy)\n",
        "### num_experiments: n of times the train code iterate on my custom dataset\n",
        "### train_from_pretrained_model: leverage transfer learning using the pretrained YOLOv3 model\n",
        "trainer.setTrainConfig(object_names_array=[\"hololens\"], batch_size=4, num_experiments=100, train_from_pretrained_model=\"pretrained-yolov3.h5\")\n",
        "trainer.trainModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcYRmT3icio"
      },
      "source": [
        "# In the sample log shown above, new models are saved based on the decrease in the validation loss. In most cases, the lower the loss, the more accurate the model will be detecting objects in images and videos. However, some models may experience overfitting and still have lower losses. To ensure that you pick the best model for your custom detection, ImageAI allows you to evaluate the mAP (mean Average Precision, read more about it here) of all the trained models saved in the hololens/models folder.\n",
        "## The higher the mAP, the better the detection accuracy of the model.\n",
        "from imageai.Detection.Custom import DetectionModelTrainer\n",
        "\n",
        "trainer = DetectionModelTrainer()\n",
        "trainer.setModelTypeAsYOLOv3()\n",
        "## other pre trained model types\n",
        "#trainer.setModelTypeAsRetinaNet()\n",
        "#trainer.setModelTypeAsTinyYOLOv3()\n",
        "trainer.setDataDirectory(data_directory='hololens')\n",
        "trainer.evaluateModel(model_path='hololens/models', json_path='hololens/json/detection_config.json', iou_threshold=0.5, object_threshold=0.3, nms_threshold=0.5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6rHGtnfixHJ"
      },
      "source": [
        "**Run custom detection code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lebl44Yixqx"
      },
      "source": [
        "# get the image to find objects\n",
        "from google.colab import files\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "img = cv2.imread('holo.JPG')\n",
        "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(img) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3V_gYqxk2Tz"
      },
      "source": [
        "from imageai.Detection.Custom import CustomObjectDetection\n",
        "\n",
        "detector = CustomObjectDetection()\n",
        "detector.setModelTypeAsYOLOv3()\n",
        "detector.setModelPath('hololens/models/detection_model-ex-034--loss-0017.824.h5') # write the best model's name here\n",
        "detector.setJsonPath('hololens/json/detection_config.json')\n",
        "detector.loadModel()\n",
        "detections = detector.detectObjectsFromImage(input_image='holo.JPG', output_image_path='obj_detected.jpg')\n",
        "\n",
        "for detection in detections:\n",
        "  print(detection['name'], \" : \", detection['percentage_probability'], \" : \", detection['box_points'])\n",
        "  print('-----')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
